{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Using datasets\n",
    "\n",
    ":::{note}\n",
    "You are viewing a working draft with expected completion in early 2025.\n",
    ":::\n",
    "\n",
    "The `nitrain.Dataset` class provides everything you need to map collections of images and related meta-data. This chapter introduces the basic functionality and structure of the class so you can get going. Once you learn the basics, it will be intuitive to expand on it with additional things you'll learn later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Besides nitrain, this chapter will use ants and numpy to create images, pandas to create some basic csv files, and some basic operating system tools to create directories that mimic what your data will look like when not loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nitrain as nt\n",
    "import ants\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in memory\n",
    "\n",
    "To create a dataset, you need to pass in `inputs` and `outputs` arguments. In the most basic example of image classification, you would pass in a list of images as inputs and a list of class labels as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ants.from_numpy(np.ones((100,100))) * i for i in range(10)]\n",
    "labels = [i for i in range(10)]\n",
    "\n",
    "dataset = nt.Dataset(inputs=images,\n",
    "                     outputs=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataset is mapped! We can retrieve a record from the dataset via indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And retrieving multiple records is also possible via indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      ", ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "]\n",
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "x_list, y_list = dataset[3:5]\n",
    "print(x_list)\n",
    "print(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the dataset to understand a bit more of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (n=10)\n",
      "     Inputs     : <nitrain.readers.memory.MemoryReader object at 0x1326f5690>\n",
      "     Outputs    : <nitrain.readers.memory.MemoryReader object at 0x1326f5dd0>\n",
      "     Transforms : {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, our dataset has a `MemoryReader` in the inputs and the outputs slot. You will learn more about readers in later chapter, but a basic explanation is that readers are what the dataset uses to feed records from a variety of sources. Since our images and labels actually exist in memory right now, a `MemoryReader` is inferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in folders\n",
    "\n",
    "When our data does not exist in memory already, we need to actually specify the source of the data with a reader. Let's start with a scenario where our images are stored in a folder and we still want to perform classification. How would the class labels be stored?\n",
    "\n",
    "One common possibilty would be for our class labels to be stored in a csv file. Then our folder might look like this:\n",
    "\n",
    "```\n",
    "mydata/\n",
    "  participants.csv\n",
    "  img0.nii.gz\n",
    "  img1.nii.gz\n",
    "  ...\n",
    "  img9.nii.gz\n",
    "```\n",
    "\n",
    "Let's create this dataset in a temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfolder = TemporaryDirectory()\n",
    "base_dir = tmpfolder.name\n",
    "\n",
    "# save images\n",
    "for i in range(10):\n",
    "    ants.image_write(images[i], os.path.join(base_dir, f'img{i}.nii.gz'))\n",
    "\n",
    "# create and save participants.csv\n",
    "dataframe = pd.DataFrame({'labels': labels})\n",
    "dataframe.to_csv(os.path.join(base_dir, 'participants.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the files in the directory shows us exactly what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img6.nii.gz', 'img4.nii.gz', 'img8.nii.gz', 'participants.csv', 'img0.nii.gz', 'img2.nii.gz', 'img7.nii.gz', 'img5.nii.gz', 'img9.nii.gz', 'img1.nii.gz', 'img3.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(base_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we want to read images from the folder and we want to read the class labels from a column in the participants.csv file. In nitrain, this corresponds to using the `ImageReader` and the `ColumnReader` classes. Here is what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nitrain import readers\n",
    "dataset = nt.Dataset(inputs=readers.ImageReader('img*.nii.gz'),\n",
    "                     outputs=readers.ColumnReader('labels', base_file='participants.csv'),\n",
    "                     base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ImageReader` class lets us map images from a glob-like pattern, while the `ColumnReader` lets us map column values from csv-like files. We also pass in a `base_dir` to make things simpler. We can read a record from this dataset exactly as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n",
      "3.0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset[3]\n",
    "print(x)\n",
    "print(x.mean())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, nitrain knew to read in the images from file and to align the image with its label. This covers the scenario of reading images from file and values from csv-like files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder names as labels\n",
    "\n",
    "Another common scenario for image classification is where images are stored into folders based on their class. In this case, the class labels are not stored in a csv-like file but are instead contained in the folder names themselves.\n",
    "\n",
    "The dataset would therefore look like this:\n",
    "\n",
    "```\n",
    "mydata/\n",
    "  class0/\n",
    "    img1.nii.gz\n",
    "    ...\n",
    "  class1/\n",
    "    img1.nii.gz\n",
    "    ...\n",
    "  ...\n",
    "```\n",
    "\n",
    "Let's create that dataset now in a temporary folder to use as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfolder = TemporaryDirectory()\n",
    "base_dir = tmpfolder.name\n",
    "\n",
    "# save images\n",
    "for i in range(10):\n",
    "    os.mkdir(os.path.join(base_dir, f'class{i}'))\n",
    "    ants.image_write(images[i], os.path.join(base_dir, f'class{i}/img1.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can list the main directory to see the structure. We can also show what's in one of the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main folder: ['class0', 'class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9']\n",
      "Sub-folder (class0): ['img1.nii.gz']\n",
      "Sub-folder (class1): ['img1.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print('Main folder:', sorted(os.listdir(base_dir)))\n",
    "print('Sub-folder (class0):', sorted(os.listdir(os.path.join(base_dir, 'class0'))))\n",
    "print('Sub-folder (class1):', sorted(os.listdir(os.path.join(base_dir, 'class1'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scenario is handled by a small update to the glob pattern in our `ImageReader` and with a different kind of reader for the outputs called `FolderNameReader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nt.Dataset(inputs=readers.ImageReader('*/img*.nii.gz'),\n",
    "                     outputs=readers.FolderNameReader('*/img*.nii.gz'),\n",
    "                     base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a record shows that the result is (nearly) the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n",
      "3.0\n",
      "class3\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset[3]\n",
    "\n",
    "print(x)\n",
    "print(x.mean())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is that since our folders were named e.g., \"class0\" instead of just \"0\", the `FolderNameReader` returned the full string name. We can change this by telling the `FolderNameReader` to format the values as integers instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "dataset = nt.Dataset(inputs=readers.ImageReader('*/img*.nii.gz'),\n",
    "                     outputs=readers.FolderNameReader('*/img*.nii.gz', format='integer'),\n",
    "                     base_dir=base_dir)\n",
    "\n",
    "x, y = dataset[3]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the same thing as before. This demonstrates the flexibility of many readers in nitrain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing readers\n",
    "\n",
    "In the above scenario, we had only a single image as input and a single value as output. However, readers can be arbitrarily combined to return multiple inputs or multiple outputs in whatever format you need. \n",
    "\n",
    "Let's take a scenario where we want to perform image segmentation - i.e., predict a label image from another image. Let's also assume that we have information about each image pair in a csv file as before. Say that our folder looks like this:\n",
    "\n",
    "```\n",
    "mydata/\n",
    "   participants.csv\n",
    "   img1-anat.nii.gz\n",
    "   img1-seg.nii.gz\n",
    "   img2-anat.nii.gz\n",
    "   img2-seg.nii.gz\n",
    "   ...\n",
    "```\n",
    "\n",
    "\n",
    "We can create this folder to use as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img0-anat.nii.gz', 'img0-seg.nii.gz', 'img1-anat.nii.gz', 'img1-seg.nii.gz', 'img2-anat.nii.gz', 'img2-seg.nii.gz', 'img3-anat.nii.gz', 'img3-seg.nii.gz', 'img4-anat.nii.gz', 'img4-seg.nii.gz', 'img5-anat.nii.gz', 'img5-seg.nii.gz', 'img6-anat.nii.gz', 'img6-seg.nii.gz', 'img7-anat.nii.gz', 'img7-seg.nii.gz', 'img8-anat.nii.gz', 'img8-seg.nii.gz', 'img9-anat.nii.gz', 'img9-seg.nii.gz', 'participants.csv']\n"
     ]
    }
   ],
   "source": [
    "tmpfolder = TemporaryDirectory()\n",
    "base_dir = tmpfolder.name\n",
    "\n",
    "for i in range(10):\n",
    "    # create image and segmentation\n",
    "    img = ants.from_numpy(np.random.randn(100,100))\n",
    "    seg = img > 0\n",
    "    \n",
    "    ants.image_write(img, os.path.join(base_dir, f'img{i}-anat.nii.gz'))\n",
    "    ants.image_write(seg, os.path.join(base_dir, f'img{i}-seg.nii.gz'))\n",
    "\n",
    "dataframe = pd.DataFrame({'labels': list(range(10))})\n",
    "dataframe.to_csv(os.path.join(base_dir, 'participants.csv'))\n",
    "\n",
    "print(sorted(os.listdir(base_dir)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous section, we can infer that having an image as input and an image as output can be handled by the `ImageReader` class with two different glob patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n",
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = nt.Dataset(inputs=readers.ImageReader('img*-anat.nii.gz'),\n",
    "                     outputs=readers.ImageReader('img*-seg.nii.gz'),\n",
    "                     base_dir=base_dir)\n",
    "\n",
    "x, y = dataset[3]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take this one step further. What if we want to also pass in a value as input to our model in addition to the image? We saw previously that values can be mapped using the `ColumnReader` if they're store in csv-like files. Therefore, it is intuitive to simply combine the readers together in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      ", 3]\n",
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = nt.Dataset(inputs=[readers.ImageReader('img*-anat.nii.gz'),\n",
    "                             readers.ColumnReader('labels', base_file='participants.csv')],\n",
    "                     outputs=readers.ImageReader('img*-seg.nii.gz'),\n",
    "                     base_dir=base_dir)\n",
    "\n",
    "x, y = dataset[3]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the input from our dataset is not a single image anymore, but an image-value pair. This handles the scenario where we want to pass multiple inputs to our model. We can also created nested inputs if we want! This can be done for both inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      ", 3], 3]\n",
      "[ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      ", ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "dataset = nt.Dataset(inputs=[[readers.ImageReader('img*-anat.nii.gz'),\n",
    "                             readers.ColumnReader('labels', base_file='participants.csv')],\n",
    "                             readers.ColumnReader('labels', base_file='participants.csv')],\n",
    "                     outputs=[readers.ImageReader('img*-seg.nii.gz'),\n",
    "                              readers.ImageReader('img*-seg.nii.gz')],\n",
    "                     base_dir=base_dir)\n",
    "\n",
    "x, y = dataset[3]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates how nitrain datasets can be used to flexibly build up any type of input-output structure that is needed. By using different readers, it's possible to map data from any local sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This chapter gave a basic introduction to using nitrain datasets. You learned about mapping data that already exists in memory, as well as data that exists locally in folders. Mapping data is done using various readers that nitrain provides. You also saw how any number of inputs and outputs can be mapped in nitrain datasets - with any arbitrary structure.\n",
    "\n",
    "In the next chapter, we will see how the same concepts can be applied to data that is neither store in memory nor locally in folders. The next chapter shows you how to instead work with data on various cloud storage platforms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
