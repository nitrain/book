{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Using datasets\n",
    "\n",
    "The `nitrain.Dataset` class provides everything you need to map collections of images and related meta-data. This chapter introduces the basic functionality and structure of the class so you can get going. Once you learn the basics, it will be intuitive to expand on it with additional things you'll learn later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Besides nitrain, this chapter will use ants and numpy to create images, pandas to create some basic csv files, and some basic operating system tools to create directories that mimic what your data will look like when not loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nitrain as nt\n",
    "import ants\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic example\n",
    "\n",
    "To create a dataset, you need to pass in `inputs` and `outputs` arguments. In the most basic example of image classification, you would pass in a list of images as inputs and a list of class labels as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ants.from_numpy(np.ones((100,100))) * i for i in range(10)]\n",
    "labels = [i for i in range(10)]\n",
    "\n",
    "dataset = nt.Dataset(inputs=images,\n",
    "                     outputs=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataset is mapped! We can retrieve a record from the dataset via indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And retrieving multiple records is also possible via indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      ", ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "]\n",
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "x_list, y_list = dataset[3:5]\n",
    "print(x_list)\n",
    "print(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the dataset to understand a bit more of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (n=10)\n",
      "     Inputs     : <nitrain.readers.memory.MemoryReader object at 0x1326f5690>\n",
      "     Outputs    : <nitrain.readers.memory.MemoryReader object at 0x1326f5dd0>\n",
      "     Transforms : {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, our dataset has a `MemoryReader` in the inputs and the outputs slot. You will learn more about readers in later chapter, but a basic explanation is that readers are what the dataset uses to feed records from a variety of sources. Since our images and labels actually exist in memory right now, a `MemoryReader` is inferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from file\n",
    "\n",
    "When our data does not exist in memory already, we need to actually specify the source of the data with a reader. Let's start with a scenario where our images are stored in a folder and we still want to perform classification. How would the class labels be stored?\n",
    "\n",
    "One common possibilty would be for our class labels to be stored in a csv file. Then our folder might look like this:\n",
    "\n",
    "```\n",
    "mydata/\n",
    "  participants.csv\n",
    "  img0.nii.gz\n",
    "  img1.nii.gz\n",
    "  ...\n",
    "  img9.nii.gz\n",
    "```\n",
    "\n",
    "Let's create this dataset in a temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfolder = TemporaryDirectory()\n",
    "base_dir = tmpfolder.name\n",
    "\n",
    "# save images\n",
    "for i in range(10):\n",
    "    ants.image_write(images[i], os.path.join(base_dir, f'img{i}.nii.gz'))\n",
    "\n",
    "# create and save participants.csv\n",
    "dataframe = pd.DataFrame({'labels': labels})\n",
    "dataframe.to_csv(os.path.join(base_dir, 'participants.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the files in the directory shows us exactly what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img6.nii.gz', 'img4.nii.gz', 'img8.nii.gz', 'participants.csv', 'img0.nii.gz', 'img2.nii.gz', 'img7.nii.gz', 'img5.nii.gz', 'img9.nii.gz', 'img1.nii.gz', 'img3.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(base_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we want to read images from the folder and we want to read the class labels from a column in the participants.csv file. In nitrain, this corresponds to using the `ImageReader` and the `ColumnReader` classes. Here is what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nitrain import readers\n",
    "dataset = nt.Dataset(inputs=readers.ImageReader('img*.nii.gz'),\n",
    "                     outputs=readers.ColumnReader('labels', base_file='participants.csv'),\n",
    "                     base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ImageReader` class lets us map images from a glob-like pattern, while the `ColumnReader` lets us map column values from csv-like files. We also pass in a `base_dir` to make things simpler. We can read a record from this dataset exactly as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n",
      "3.0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset[3]\n",
    "print(x)\n",
    "print(x.mean())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, nitrain knew to read in the images from file and to align the image with its label. This covers the scenario of reading images from file and values from csv-like files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder names as labels\n",
    "\n",
    "Another common scenario for image classification is where images are stored into folders based on their class. In this case, the class labels are not stored in a csv-like file but are instead contained in the folder names themselves.\n",
    "\n",
    "The dataset would therefore look like this:\n",
    "\n",
    "```\n",
    "mydata/\n",
    "  class0/\n",
    "    img1.nii.gz\n",
    "    ...\n",
    "  class1/\n",
    "    img1.nii.gz\n",
    "    ...\n",
    "  ...\n",
    "```\n",
    "\n",
    "Let's create that dataset now in a temporary folder to use as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfolder = TemporaryDirectory()\n",
    "base_dir = tmpfolder.name\n",
    "\n",
    "# save images\n",
    "for i in range(10):\n",
    "    os.mkdir(os.path.join(base_dir, f'class{i}'))\n",
    "    ants.image_write(images[i], os.path.join(base_dir, f'class{i}/img1.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can list the main directory to see the structure. We can also show what's in one of the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main folder: ['class0', 'class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9']\n",
      "Sub-folder (class0): ['img1.nii.gz']\n",
      "Sub-folder (class1): ['img1.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print('Main folder:', sorted(os.listdir(base_dir)))\n",
    "print('Sub-folder (class0):', sorted(os.listdir(os.path.join(base_dir, 'class0'))))\n",
    "print('Sub-folder (class1):', sorted(os.listdir(os.path.join(base_dir, 'class1'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scenario is handled by a small update to the glob pattern in our `ImageReader` and with a different kind of reader for the outputs called `FolderNameReader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nt.Dataset(inputs=readers.ImageReader('*/img*.nii.gz'),\n",
    "                     outputs=readers.FolderNameReader('*/img*.nii.gz'),\n",
    "                     base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a record shows that the result is (nearly) the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (100, 100)\n",
      "\t Spacing    : (1.0, 1.0)\n",
      "\t Origin     : (0.0, 0.0)\n",
      "\t Direction  : [1. 0. 0. 1.]\n",
      "\n",
      "3.0\n",
      "class3\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset[3]\n",
    "\n",
    "print(x)\n",
    "print(x.mean())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is that since our folders were named e.g., \"class0\" instead of just \"0\", the `FolderNameReader` returned the full string name. We can change this by telling the `FolderNameReader` to format the values as integers instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "dataset = nt.Dataset(inputs=readers.ImageReader('*/img*.nii.gz'),\n",
    "                     outputs=readers.FolderNameReader('*/img*.nii.gz', format='integer'),\n",
    "                     base_dir=base_dir)\n",
    "\n",
    "x, y = dataset[3]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the same thing as before. This demonstrates the flexibility of many readers in nitrain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple inputs or outputs\n",
    "\n",
    "In the above scenario, we had only a single image as input and a single value as output. However, readers can be arbitrarily combined to return multiple inputs or multiple outputs in whatever format you need. \n",
    "\n",
    "Let's start with a simpler scenario where we want to perform image segmentation - i.e., predict a label image from another image. Say that our folder looks like this:\n",
    "\n",
    "```\n",
    "mydata/\n",
    "   img1.nii.gz\n",
    "   img1-seg.nii.gz\n",
    "   img2.nii.gz\n",
    "   img2-seg.nii.gz\n",
    "   ...\n",
    "```\n",
    "\n",
    "\n",
    "We can create this folder and then map a nitrain dataset using the `ImageReader` class as input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
